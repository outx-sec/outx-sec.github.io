<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PR - Fuzzing: a survey</title>
      <link href="/2020/06/18/Fuzzing%20a%20survey/"/>
      <url>/2020/06/18/Fuzzing%20a%20survey/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>原文作者：J Li, B Zhao, C Zhang</em></p><p><em>原文标题: Fuzzing a survey</em></p><p><em>原文链接: <a href="https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf">https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf</a></em></p><p><em>原文来源: <a href="https://cybersecurity.springeropen.com/">Cybersecurity</a></em></p><p><em>笔记作者：outx</em></p></blockquote><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>​    互联网和世界数字经济运行在一个共享的、关键的开源软件（OSS）基础设施上。单个库中的安全缺陷可能会产生严重后果。例如，OpenSSL实现了用于安全通信的协议，并被包括大多数HTTPS网站在内的Internet服务器广泛使用。早期版本的OpenSSL中的“心脏滴血”漏洞会泄露机密数据并造成巨大的经济损失。目前，fuzzing是这方面最有前途的技术之一，现阶段有三种主要的fuzzing技术：黑盒，灰盒和白盒fuzzing。</p><p>​    黑盒fuzzing是在不了解程序内部构造的情况下产生输入的。其有两个主要的变种：突变型和生成型。在突变型黑盒fuzzing中，fuzzing从一个或多个种子输入开始。这些种子被修改以产生新的输入。随机突变被应用于输入中的随机位置。在生成型黑fuzzing中，输入是从头开始生成的。 如果提供了输入格式的结构规范，就会以此生成符合语法规范的新输入。Peach是一个流行的黑盒fuzzing工具。</p><p>​    灰盒fuzzing往往会利用程序来获得轻量级的反馈，用于指导fuzzer的工作。通常来说，程序中的一些控制位置在编译时进行检测，并提供初始种子语料库。 种子输入被改变以产生新的输入。产生的输入覆盖了新的控制位置，从而增加了代码覆盖率，进而被添加到种子语料库中。覆盖率反馈允许灰盒fuzzing逐渐深入到代码中。为了识别错误和漏洞，清理程序会将断言注入到程序中。现有的灰盒Fuzzing工具包括AFL、LibFuzzer和Honggfuzz。</p><p>​    白盒fuzzing技术是基于一种叫做符号执行的技术，它使用程序分析和约束解算器来系统地列举可能出现漏洞的程序路径。 在白盒fuzzing中用作后台的约束解算器是Satisfiability Modulo Theory(SMT)解算器，它允许对（无量子）一阶逻辑公式进行推理，其平等和函数/谓语符号来自不同的背景理论。白盒fuzzer会计算一个输入i的路径条件与i走过相同路径的输入集合。给定一个种子输入，计算并改变路径条件（与改变程序输入相反）。改变路径条件然后被发送到约束解算器以生成新的输入。这种技术的主要优点是其能够通过跟踪到目前为止的所有输入的路径条件，生成一个穿过新路径（新控制流）的输入。现有的白盒模糊工具包括KLEE和SAGE。</p><h1 id="Fuzzing原理"><a href="#Fuzzing原理" class="headerlink" title="Fuzzing原理"></a>Fuzzing原理</h1><h2 id="Fuzzing的工作流程"><a href="#Fuzzing的工作流程" class="headerlink" title="Fuzzing的工作流程"></a>Fuzzing的工作流程</h2><p>​    下图描述了传统Fuzzing的工作流程，由四个主要阶段组成，即测试用例生成阶段、测试用例运行阶段、程序执行状态监控和异常分析。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/image-20210618145110707.png" alt="image-20210618145110707"></p><p>​    Fuzzing是从生成一堆程序输入开始的，也就是测试用例。生成的测试用例的质量直接影响测试效果。输入应该尽可能地满足被测程序对输入格式的要求。而另一方面，输入应该足够碎片化，以便在图1的模糊测试工作过程中导致程序执行出现问题。根据目标程序，输入可以是不同文件格式的文件、网络通信数据、具有特定特征的可执行二进制文件等。如何产生足够多的测试用例是现阶段Fuzzing的主要挑战。一般来说，最先进的模糊器使用两种生成器，即基于生成的生成器和基于变异的生成器。测试用例在上一阶段生成后被送入目标程序。模糊器自动启动和完成目标程序的过程，并驱动目标程序的测试用例处理过程。在执行之前，分析人员可以配置目标程序的启动和结束方式，并预先定义参数和环境变量。通常情况下，模糊处理过程会在预定义的超时、程序执行挂起或崩溃时停止。Fuzzer会在目标程序的执行过程中监测执行状态，期待异常和崩溃。常用的异常监测方法包括对特定系统信号的监测、崩溃和其他违规行为。对于没有直观程序异常行为的违规行为，可以使用很多工具，包括AddressSanitizer、DataFlowsanitizer、ThreadSanitizer、LeakSanitizer等。当捕捉到违规行为时，Fuzzer会存储相应的测试用例，供后者回放和分析。在分析阶段，分析员试图确定捕获的违规行为的位置和根本原因。分析通常在调试器的帮助下进行，如GDB、windbg，或其他二进制分析工具，如IDAPro、OllyDbg等。二进制工具，如Pin，也可以用来监测收集的测试用例的确切执行状态，如线程信息、指令、寄存器信息等等。</p><h2 id="Fuzzer的分类"><a href="#Fuzzer的分类" class="headerlink" title="Fuzzer的分类"></a>Fuzzer的分类</h2><p>​    Fuzzer可以以各种方式进行分类，主要分为基于生成的和基于突变的[8]。</p><p>​    对于基于生成的Fuzzer，需要了解程序输入的知识。对于文件格式的Fuzzing，通常需要提供一个预先定义文件格式的配置文件。测试用例是根据配置文件生成的。有了给定的文件格式，由基于生成的Fuzzer生成的测试用例能够更容易地通过程序的验证，并更有可能测试目标程序的深层代码。然而，如果没有一个好的文件，分析文件格式是一项艰难的工作。因此，基于突变的Fuzzer更容易启动，也更适用。对于基于突变的模糊器，需要一组有效的初始输入。测试用例是通过初始输入的突变和Fuzzing过程中产生的测试用例产生的。下表中比较了基于生成的fuzzers和基于突变的fuzzers。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/image-20210618145552977.png" alt="image-20210618145552977"></p><p>​    就对程序源代码的依赖性和程序分析的程度而言，Fuzzing技术可以被分为白盒、灰盒和黑盒。白盒可以接触到程序的源代码，因此可以通过对源代码的分析收集更多的信息，包括测试用例如何影响程序的运行状态。黑盒是指在不了解目标程序内部的情况下进行Fuzzing。灰盒测试在没有源代码的情况下也能工作，并通过程序分析获得目标程序的内部信息。下表中列出了一些常见的白盒、灰盒和黑盒fuzzer。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/image-20210618145642592.png" alt="image-20210618145642592"></p><p>​    根据遍历程序代码的策略，可以将Fuzzer分为定向Fuzzing和基于覆盖的Fuzzing。有方向的Fuzzer旨在生成覆盖程序的目标代码和目标路径的测试用例，而基于覆盖的Fuzzer旨在生成覆盖尽可能多程序代码的测试用例。定向Fuzzing希望对程序进行更快的测试，而基于覆盖的Fuzzing则希望进行更彻底的测试，并尽可能地检测更多的错误。但对于这两种测试方法而言，如何提取执行路径的信息是一个关键问题。</p><p>​    根据对程序执行状态的监控和测试用例的生成之间是否存在反馈，可以将模糊器分为无反馈Fuzzer和智能Fuzzer。智能Fuzzer根据收集到的信息调整测试用例的生成，即测试用例如何影响程序行为。对于基于突变的Fuzzer，反馈信息可用于确定哪部分测试用例应该被突变以及突变的方式。无反馈Fuzzer获得了更好的测试速度，而智能Fuzzer产生了更好的测试用例并获得了更好的效率。</p><h1 id="Fuzzing中的关键挑战"><a href="#Fuzzing中的关键挑战" class="headerlink" title="Fuzzing中的关键挑战"></a>Fuzzing中的关键挑战</h1><p>​    传统的Fuzzer在实践中通常采用基于随机的Fuzzing策略。程序分析技术的局限性导致了现在的状况，即Fuzzer不够智能。因此，Fuzzing仍然面临许多挑战。我们列出一些关键的挑战如下：</p><h2 id="如何对种子输入进行突变"><a href="#如何对种子输入进行突变" class="headerlink" title="如何对种子输入进行突变"></a>如何对种子输入进行突变</h2><p>​    基于突变的生成策略因其方便和容易设置而被最先进的Fuzzer广泛使用[9]。然而，如何变异并生成能够覆盖更多程序路径和更容易触发错误的测试用例是一个关键的挑战。具体来说，基于突变的Fuzzer在进行突变时需要解决两个问题：</p><ul><li>在哪里突变</li><li>如何突变</li></ul><p>​    只有少数关键位置的突变会影响执行的控制流程。因此，如何定位这些关键位置是非常重要的。此外，Fuzzer对关键位置的突变方式是另一个关键问题，即如何确定可以将测试引向程序的有潜在危险路径的值。总而言之，盲目的突变测试用例会造成测试资源的严重浪费，而更好的突变策略可以显著提高模糊测试的效率。</p><h2 id="低代码覆盖率"><a href="#低代码覆盖率" class="headerlink" title="低代码覆盖率"></a>低代码覆盖率</h2><p>​    更高的代码覆盖率代表了更高的程序执行状态覆盖率，以及更彻底的测试。先前的一些工作已经证明，覆盖率越高，发现问题的概率就越大。然而，大多数测试用例只覆盖了相同的几条路径，而大部分的代码逻辑却无法触及。因此，仅仅通过大量的测试用例生成和投入测试资源来实现高覆盖率并不是一个明智的选择。基于覆盖率的Fuzzer将在程序分析技术的帮助下解决这个问题，比如程序分析工具。</p><h2 id="通过验证"><a href="#通过验证" class="headerlink" title="通过验证"></a>通过验证</h2><p>​    程序通常在解析和处理之前对输入进行验证。验证的作用是保护程序，节省计算资源，保护程序免受无效输入和恶意构建的输入所造成的损害。无效的测试用例总是被忽略或丢弃的。Magic numbers、Magic strings、版本号检查和校验是程序中常用的验证方法。黑盒和灰盒Fuzzer生成的测试用例很难通过生成策略的验证，这会导致Fuzzing处理的效率相当低。因此，如何通过验证是另一个关键挑战。</p><h1 id="Fuzzing的新趋势"><a href="#Fuzzing的新趋势" class="headerlink" title="Fuzzing的新趋势"></a>Fuzzing的新趋势</h1><p>​    作为一种自动检测漏洞的方法，Fuzzing已经显示出它的高效力和高效率。然而，正如第三节所述，仍有许多挑战需要解决。在本节中，我们简单介绍一下自己关于Fuzzing发展趋势的理解。</p><p>​    首先，智能Fuzzing技术为Fuzzing的改进提供了更多可能性。在以前的工作中，传统的静态和动态分析被整合到Fuzzing中，以帮助改善这一过程。整体上来看已经有了一定的改进，但还是很有限。智能Fuzzing技术通过各种方式收集目标程序的执行信息，能够对Fuzzing过程进行了更精细的控制，并提出了很多Fuzzing策略。随着对不同类型漏洞的深入了解，并利用漏洞的特点进行模糊处理，智能模糊处理可以帮助发现更复杂的漏洞。</p><p>​    第二，新技术可以在许多方面帮助改善脆弱性。机器学习和相关技术等这类新兴技术已经被用来改善模糊测试中的测试用例生成。如何将新技术的优势和特点与Fuzzing结合起来，如何将Fuzzing中的关键挑战转化或分割成新技术所擅长的问题，是另一个值得考虑的问题。</p><p>​    第三，新的系统特征和硬件特征也不应该被忽视。根据前人的一些工作我们可以知道新的硬件特性能够极大地提高Fuzzing的效率。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>​    Fuzzing是目前最有效和最高效的漏洞发现方案。在本文中，我们对Fuzzing方法及其最新进展做了全面的回顾和总结。首先我们介绍了Fuzzing的基本原理和工作流程，然后我们介绍了Fuzzing的基本分类标准。同时，我们还介绍了Fuzzing在这些年的发展过程中遇到的问题和挑战。最后，我们总结了与Fuzzing相结合的技术，以及Fuzzing的应用和可能的新趋势。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Survey </tag>
            
            <tag> Fuzzing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conference - InForSec</title>
      <link href="/2020/06/06/Inforsec%20Learning/"/>
      <url>/2020/06/06/Inforsec%20Learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>北京之旅</em></p></blockquote><h1 id="Session-1"><a href="#Session-1" class="headerlink" title="Session 1"></a>Session 1</h1><h2 id="Precisely-Characterizing-Security-Impact-in-a-Floodof-Patches-via-Symbolic-Rule-Comparison"><a href="#Precisely-Characterizing-Security-Impact-in-a-Floodof-Patches-via-Symbolic-Rule-Comparison" class="headerlink" title="Precisely Characterizing Security Impact in a Floodof Patches via Symbolic Rule Comparison"></a>Precisely Characterizing Security Impact in a Floodof Patches via Symbolic Rule Comparison</h2><p><strong><em>Q: 为什么要识别与安全相关的 bug？</em></strong><br>作者在探究之初提出了上述这个问题，然后围绕这个问题进行了很多思考，得出了以下的两点继续研究的动机;</p><ol><li>bug 报告数量很大</li><li>补丁与代码的传播不及时</li></ol><p>以上两点总结起来可以理解为现有的一些项目或者代码的维护者的数量是有限的，同时每个人的精力也是有限的。对于每天上报的 bug 报告，维护者很难及时和全面的审查这些报告。为此，作者提出了以下 Goal：</p><p><strong><em>Goal: 识别与安全相关的漏洞补丁</em></strong><br>具体来说，识别与安全相关的漏洞补丁能够让一些项目或者代码的维护者能够及时的打上那些威胁严重的安全漏洞补丁以防止被恶意攻击者攻击，而不用耗费精力在修复那些无关紧要的 bug。</p><p><strong>传统方法</strong><br>传统的识别方法主要有：</p><ol><li>文本分析：主要是依靠关键字分析</li><li>统计分析：主要是依靠分析趋势</li></ol><p>但传统方法具有很明显的局限性，一是其精度难以保证，二是维护者难以判断 bug 的影响力。</p><p><strong>通用代码安全规则和违规行为</strong></p><ol><li>界内访问（内存、数组）—— 越界访问(out-of-bound access)</li><li>不允许指针等 free 后被再使用 —— free 后重用(use-after-free)</li><li>变量应初始化后使用 —— 未初始化使用(uninitialized use)</li><li>敏感操作前的权限检查 —— 绕过权限(permission bypass)</li></ol><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/9a3cab95-0dd9-4d1d-b526-7527e7741f65.png"></p><p>基于以上通用代码安全规则和其对应的违规行为，作者提出了一个定义：给定一个代码和补丁，在没有打补丁的情况下，代码会违反以上安全规则。</p><p><strong>SID 整体结构</strong><br>根据上述定义，作者提出了 SID，这是一个基于 LLVM 的解决方案，其框架如下<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/d90df980-318e-4d96-8d8a-c78097e800b2.png"></p><p>主要分为三部分：预处理，剖析补丁，符号规则比较</p><ol><li>预处理</li></ol><p>在预处理部分，作者首先根据 bug 补丁将软件的版本分为打了补丁的版本和没有打补丁的版本，然后分别调用 LLVM 将其编译为对应的 LLVM IRS。</p><ol start="2"><li>剖析补丁</li></ol><p>主要是通过静态分析来对不同版本的代码进行分析。在这个阶段，SID 根据补丁模型对补丁进行剖析，以确定关键组件。SID 首先识别出打过补丁和没有打过补丁的版本中的安全操作。接下来，SID 对关键变量进行数据流分析，以收集存在漏洞的代码片段。</p><ol start="3"><li>符号规则比较</li></ol><ul><li>对于打了补丁的版本<br>在打了补丁的版本中，存在的漏洞往往是存在于补丁之后。例如，对于越界访问来说，通常补丁会在进行访问操作之前校验访问的空间是否是正确的。换句话来说，在打了补丁的版本中，违反安全规则这一行为是不存在的，即打了补丁的版本不存在相应的漏洞。</li><li>对于没打补丁的版本<br>对于没有打补丁的版本，由于其存在漏洞的代码是程序执行流程中可达的，因此执行程序的过程中是会出发漏洞的。换句话来说，对于没有打补丁的版本来说，不违反安全规则这一行为是不存在的，即没有打补丁的版本一定存在相应的漏洞。</li></ul><p>通过这两方面的约束，才能够证明这个补丁修复的是一个安全相关的 bug。</p><p><strong>方法表现</strong><br>作者分析了 54K 的补丁，平均对每个补丁的分析时间为 0.83 秒。同时，作者主要从假阳性和假阴性两方面来分析</p><ol><li>假阳性分析<br>作者通过 SID 共计找出了 227 个安全相关的 bug，其中仅有 8 个假阳性的样例</li><li>假阴性分析<br>53%的假阴性，绝大部分都是因为对安全代码和漏洞代码的覆盖不完全导致的，这是有待改进的地方。</li></ol><p><strong>总结</strong></p><ul><li>及时修补安全漏洞需要确定安全影响<ul><li>补丁的传播成本很高，维护者时间和精力有限</li><li>为此，维护者需要确定和及时修复那些与安全相关的 bug</li></ul></li><li>使用受约束的符号执行的特性来确定哪些是与安全相关的 bug，哪些是常规的 bug<ul><li>SID：符号规则比较</li></ul></li><li>SID 发现了内核中许多被忽视的安全漏洞</li></ul><h1 id="Session-2"><a href="#Session-2" class="headerlink" title="Session 2"></a>Session 2</h1><h2 id="Automatic-Policy-Generation-for-Inter-Service-Access-Control-of-Microservices"><a href="#Automatic-Policy-Generation-for-Inter-Service-Access-Control-of-Microservices" class="headerlink" title="Automatic Policy Generation for Inter-Service Access Control of Microservices"></a>Automatic Policy Generation for Inter-Service Access Control of Microservices</h2><p><strong>研究背景</strong><br>云应用架构的演进，从传统的模块紧耦合、不易维护和扩展的单体架构演变为将模块解耦、独立开发和部署的微服务架构，再到统一管理服务间通信的服务网格。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/eade3d98-e479-498d-8e0e-2691b4d25601.png"></p><p><strong>研究动机</strong><br>首先是微服务之间通过网络 API 的通信方式会带来一些新的攻击面。其次，不安全的容器镜像可能会导致容器被渗透。</p><p>一个具体的例子：</p><ul><li>威胁：被攻破的微服务可能通过恶意请求窃取数据或发起攻击</li><li>对策：服务间细粒度的访问控制</li></ul><p>现在的微服务应用具有规模庞大且频繁更新的特点，如果手工配置访问控制策略的话，不仅耗时巨大且容易出错，也相对没那么灵活。</p><p>现有的分布式系统中的安全策略自动化方法：</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/8ed93ef9-3bda-4404-9425-eb29775f6811.png"></p><p><strong>设计思路</strong><br>微服务应用的特点：</p><ul><li>单个微服务的内部复杂度较低</li><li>单个应用类<ul><li>微服务间的调用方式相对统一</li><li>涉及到的服务间调用协议和调用库的数量也十分有限</li></ul></li></ul><p>结合以上特点，作者采用了通过静态分析的方式从微服务代码中提取其正常的系统行为。<br>于是作者便提出了：<br><em>GOAL: 自动生成、维护、更新微服务的服务间访问控制策略</em><br><em>Challenge：如何获取完整、细粒度的服务间调用逻辑；如何对服务间的访问控制策略进行高效的生成和更新</em></p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/7d66b478-8d85-46b0-8574-dd46510184af.png"><br><em>基于静态分析的微服务间调用请求提取</em><br>具体来说分为三步：第一步识别网络 API 调用语句，即发起服务间调用的关键语句；第二步以第一步获取的关键语句为起点，沿数据流反向进行污点传播，获取程序切片；第三步通过语义分析在程序切片中提取服务间调用的详细属性。</p><p><em>基于图的微服务间访问控制策略管理</em><br>运行时的策略检查时间随着安装的服务间访问控制策略数目线性增加，这会造成整个微服务应用性能下降。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/c43d41df-d252-40bc-b189-b6413e3bc57b.png"></p><p>往往同一微服务可能会存在不同版本在同一时间提供不同的服务，这又会造成冗余，于是作者提出了一种优化思路：将同一服务的各版本共有的权限进行整合。这既消除了冗余，减少了策略总数，又消除了不必要的策略更新。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/0c1b8d6e-f1d6-474b-83f3-ebe06a734434.png"></p><p><strong>AUTOARMOR</strong></p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/85a45a24-0b14-4f3f-94b8-5a1f5ce33a3b.png"><br>AUTOARMOR 主要由三部分构成：</p><ol><li>静态分析引擎<br>服务 E 代码提交，静态分析引擎生成清单文件描述其发起的调用。</li><li>权限引擎<br>在 E 部署时，权限引擎获取其清单文件，生成权限节点加入权限图</li><li>策略生成器<br>策略生成器根据权限图的变化生成并下发访问控制策略。</li></ol><p>策略生成：将与当前权限节点相关的每个请求边翻译成一条服务间访问控制策略；如果一个调用请求的目标微服务尚未部署，就不授予微服务相应的权限</p><p>策略更新：版本更新对应版本节点的添加；版本回滚对应版本节点的删除</p><p><strong>总结</strong><br>AUTOARMOR 是第一个微服务间访问控制策略自动生成的解决方案。主要涉及到的一些技术有：</p><ul><li>一个基于静态分析的微服务间调用请求自动提取机制</li><li>一个基于图的自动化为服务间访问控制策略管理机制</li></ul><p>AUTOARMOR 可以有效地实现微服务间访问控制策略的自动生成、维护和更新，但只引入极小的性能开销。</p><h1 id="Session-3"><a href="#Session-3" class="headerlink" title="Session 3"></a>Session 3</h1><h2 id="Understanding-Audit-Logs-Techniques-Experience-and-Requirements"><a href="#Understanding-Audit-Logs-Techniques-Experience-and-Requirements" class="headerlink" title="Understanding Audit Logs: Techniques, Experience, and Requirements"></a>Understanding Audit Logs: Techniques, Experience, and Requirements</h2><p>作者首先分享了其对于研究的一些理解和经验</p><p><strong>计算机系统研究的维度</strong><br>通常来说，开始一项研究往往由 Project/Paper 开始，向下是其具体的 Implementation，向上是其抽象的 Thesis/Theme。<br>对于 Thesis/Theme 来说，研究者需要将不同的 Claim 归纳为 Statement。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/5b32be9f-76f4-4311-94e1-a02db952a7ed.png" style="zoom: 70%;"><br>然后需要再将这些 Statement 进行总结，带入自己的一些想法，以形成在自己研究领域中的 View/Insight/Philosophy。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/2a9287d3-c7bc-4905-9842-c329999a9df1.png" style="zoom: 70%;"><br>而对于不同的 Implementation，研究者需要再将其转换为 Tool/System/Platform，以方便纵向研究时能够较好地节省重复工作的成本。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/09c41055-2cee-47aa-a210-31a72bd646d6.png" style="zoom: 70%;"></p><p>综合来说，作为一名研究者，他应该既能写 paper 也能写工具，而读 pape 的目的是要去理解这些已有工作之间的关系，找出其中还没有做或者说还有待改进的地方。当你对于一个领域有一个稳定的 view 的时候才能够更好更深地去看待一个问题，以此来找 idea。</p><p><strong>系统研究的维度</strong><br>人与系统的相互影响如下<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/d1506cfb-8d50-4387-89c0-1728b9d6cb14.png" style="zoom: 70%;"></p><ul><li>系统对系统的影响<br>系统与系统之间往往是孤立的，相应的要分析系统与系统之间的关系也就是分析不同系统之间的关联性</li><li>系统对人的影响<br>系统需要人来操作，相应的系统赋予了人有一定的责任来对系统负责</li><li>人对系统的影响<br>在系统中加入人的因素，而人往往是一个完备系统中的弱点。</li><li>人对人的影响<br>人对人的影响往往更多是在人类社会中的法律，伦理等问题上的影响。</li></ul><p><strong><em>Q: 怎么选取和开启一条线的研究?</em></strong><br>首先就是要多读这个领域相关的一些论文，在读这些论文的过程中需要体系化的总结。最终的目的是要发现一个缺失的研究点以此找到研究动机。其次，当要解决自己提出的问题，即当找解决方法的时候，可以找其他领域的解决方案然后将其映射到自己的领域里。当然，这个过程中会遇到一些新的挑战，这需要靠自己前期积累的一些背景知识来解决。</p><p>总的来说，找到一个感兴趣的新方向，第一是总结前几十年的前人的工作，完备自己的知识储备；第二就是读其他领域的论文，找到解决方案来解决遇到的研究问题。同时，当要将一条研究线做深的时候，后续的代码可以依据前一次实验的基础，例如将一个论文的实现做成 tool 或者 system。</p><p><strong>端点监视解决方案记录用于攻击调查的审计日志</strong><br>审计日志：</p><ul><li>表示 OS 级活动的事件历史记录</li><li>通过数据证明为安全事件提供可见性</li></ul><p><strong>行为抽象中的挑战</strong></p><ol><li>事件语义推断：日志记录一般用途的系统活动，但缺乏高级语义的知识</li><li>个人行为识别：审计日志的数量是十分庞大的</li></ol><p><strong>Insights</strong><br>Q: 分析者如何手动解释审计事件的语义？</p><ol><li>通过审计事件中的上下文信息来揭示系统实体和关系的语义。提取这种上下文语义的一般方法是采用嵌入模型，目的是将系统实体和关系映射到嵌入空间（即数字矢量空间）。</li><li>识别基于数据对象的信息流的行为。文中具体指的是属于个人行为的审计事件，主要是围绕着用户的预期目标，可以反映为一系列应用于数据对象的系统操作。如下图做一次审计事件的简化。<img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/1d8d7347-39f5-4afd-9a06-bdde9859e815.png" style="zoom: 70%;"></li></ol><p><strong>WATSON</strong><br>WATSON 是一种自动化的行为抽象方法，它聚集了审计事件的语义来模拟行为模式。它不需要专家对事件语义的了解来执行行为抽象。语义是从审计日志中的事件使用背景中自动获得的，这个背景被称为是事件的上下文语义。具体来说，WATSON 首先利用基于翻译的嵌入模型来推断审计事件的语义，其依据是日志中的语境信息。 然后，WATSON 识别出与相关数据对象（即文件和网络套接字）相连的事件，并将其语义汇总为高级行为的表示。最后，WATSON 对审计日志中记录的类似行为进行聚类，并区分出其中的代表，供分析人员调查。</p><p>简而言之，WATSON 是一种自动的行为抽象方法，它聚合了审计日志的语义来建模行为模式。其输入为审计日志(Linux Audit)，输出则是具有代表性的行为。</p><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/7a6aa663-2228-430a-9da0-a6eea26f1211.png"></p><p>WATSON 弥补了低级审计日志与高级系统行为之间的语义鸿沟：</p><ul><li>在基于日志的 KG 中使用上下文信息（事件语义推断）</li><li>在语义上聚类相似行为（行为总结）</li></ul>]]></content>
      
      
      <categories>
          
          <category> Conference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InForSec 2021 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PR - Fingerprinting the Fingerprinters: Learning to Detect Browser Fingerprinting Behaviors</title>
      <link href="/2020/06/01/Fingerprinting%20the%20Fingerprinters/"/>
      <url>/2020/06/01/Fingerprinting%20the%20Fingerprinters/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>原文作者：Assel Aliyeva, Manuel Egele</em></p><p><em>原文标题: Oversharing Is Not Caring: How CNAME Cloaking Can ExposeYour Session Cookies</em></p><p><em>原文链接: <a href="https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf">https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf</a></em></p><p><em>原文来源: AsiaCCS 2021</em></p><p><em>笔记作者：outx</em></p></blockquote><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>互联网发展至今，一些在线业务通常会利用第三方的分析服务来深入了解其用户的行为。但由于隐私保护的发展及浏览器同源策略的限制，这在很大程度上限制了第三方Cookie的跟踪和使用。于是，企业开始尝试将第三方分析服务伪装成其网站的子域。这种被称为是CNAME伪装的技术使得企业能够继续监测其网站上的用户活动。但随之而来的是严重的安全隐患，因为企业与这些第三方分析服务提供商共享了用户会话Cookie，这使得在线用户的账户始终处于不安全的状态。在这篇文章中，作者演示了CNAME伪装以及Lax Cookie访问控制设置对Web用户安全性的影响。为了解决这一问题，作者构建了一个可以检测伪装为子域的第三方分析服务以及第一方Cookie泄露的工具TAFinder。</p><h1 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h1><ul><li>确定了第一方Cookie泄露给T/A(跟踪和广告)服务提供商的情况</li><li>构建了TAFinder用于自动识别网站中是否存在隐匿域并检测这些Cookie是否泄漏到这些域</li><li>针对这些隐匿域提出了一种基于HTTP的Web分析域检测机制，达到了96％的准确率</li><li>确定了2,139个在野的Web分析域</li><li>对100,000个最受欢迎的网站进行了测试，发现2,271个网站使用CNAME伪装技术将第三方分析服务作为其子域</li></ul><h1 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h1><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/749afbc8-7bb7-4449-9adf-28f0710e32bb.png"><br>TAFinder主要分为三个单元：</p><ol><li>数据采集</li><li>DNS处理</li><li>基于机器学习的检测<h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2>以流水线的方式设计的TAFinder接受一个网站列表作为输入，然后由任务分配器将其分配给Worker。当从任务分配器中收到一个新的W(Website)时，一个Worker会生成一个新的爬虫实例。爬虫访问W，同时记录网络数据包和纯文本的HTTP请求/响应，并最终将捕获的数据传输给DNS处理单元。值得注意的是，Worker运行在独立的容器中，因此它允许TAFinder轻松地分离来自不同网站的网络流量。</li></ol><h2 id="DNS处理"><a href="#DNS处理" class="headerlink" title="DNS处理"></a>DNS处理</h2><p>TAFinder从任何给定的W中提取一组隐匿域CW。DNS处理单元对涉及CNAME的W的每个子域进行DNS解析链的遍历。如果一个解析链以属于第三方的CNAME结束，DNS处理单元将相应的子域标记为隐匿域D。</p><h2 id="基于机器学习的检测"><a href="#基于机器学习的检测" class="headerlink" title="基于机器学习的检测"></a>基于机器学习的检测</h2><p>TAFinder首先使用黑名单和Virus Total将CW中的域识别为T/A服务。为了将CW中剩余的未标记的隐匿域分类为T/A或非T/A，TAFinder部署了一种监督机器学习方法。为此，其设计了九种特征，以捕捉T/A服务固有的行为模式。这些特征是从访问W时与隐匿域的HTTP通信中提取的。<br>下面是九个特征:</p><ol><li>当加载W的所有资源时，以D为目标的HTTP请求的数量超过所有HTTP请求的数量</li><li>当加载W的所有资源时，来自D的HTTP响应的总大小超过所有HTTP响应大小的总和</li><li>D所设置的cookies总数</li><li>在D设置的所有cookies数量中，长cookies的数量</li><li>D设置的常规的非目标cookies的数量</li><li>D设置的常规的目标cookie的数量<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/8ab9b802-d526-4eb1-b228-85fe9b95ed0f.png"></li><li>在URL中使用的参数数量超过了以D为目标的HTTP请求的数量</li><li>目标为D的URL中包括W的域名作为参数值之一的次数</li><li>Content-Type特征<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/f4341811-3dc8-417f-a9d1-44d6ecc95c1a.png"></li></ol><p><strong>特征重要性排序</strong><br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/b679fc1b-c741-44e2-8eb2-6ae183fcebcd.png"></p><h1 id="系统实现"><a href="#系统实现" class="headerlink" title="系统实现"></a>系统实现</h1><h2 id="数据采集和DNS处理"><a href="#数据采集和DNS处理" class="headerlink" title="数据采集和DNS处理"></a>数据采集和DNS处理</h2><p>在数据采集单元，TAFinder采用了RabbitMQ来实现任务分配，这使得作者可以并行扩展和运行10个Worker。每个Worker由一个独立运行的Linux容器表示，这些容器均配置好了Tcpdump和MitmProxy用于记录网络数据包和纯文本的HTTP请求/响应。Worker使用一个基于selenium的爬虫来启动对每个单独的网站的爬取。在爬取完毕后销毁实例，压缩并将捕获到的数据存储下来。在DNS处理单元则使用了Python的Scapy库分别提取每个网站的隐匿域。</p><h2 id="基于机器学习的检测-1"><a href="#基于机器学习的检测-1" class="headerlink" title="基于机器学习的检测"></a>基于机器学习的检测</h2><p>TAFinder是靠一份T/A列表（来源包括了已被标记的第三方分析服务提供商和VirusTotal等）来标记要提取的隐匿域。同时，根据VirusTotal提供的类别来标记数据集中的在野隐匿域。</p><p>TAFinder使用MitmProxy的Python模块解析这些数据，并从中提取特征。同时。鉴于有一大批不同的cookie名称需要分类，TAFinder只选取那些最流行的cookie。为此，作者提取了所有隐匿域的HTTP响应中的cookie名称。然后，根据发送cookie的隐匿域的数量对cookie进行排名。以同样的方式，作者又创建了两个流行度排名，专门针对非T/A和T/A服务设置的cookies。</p><p>作者从上面cookie排名中选中了最受欢迎的25个cookie，以及60个隶属于T/A和非T/A域的cookie名称。根据One Trust的cookie分类，作者将这些cookie归类为T/A cookie，然后通过Cookiepedia或T/A特定的方式进行访问。基于这种方法，作者发现了27个跟踪相关的cookies和28个默认的网络应用程序cookies。</p><p>为了对隐匿域进行分类，TAFinder使用Scikit-Learn的随机森林模型。</p><h1 id="方法评估"><a href="#方法评估" class="headerlink" title="方法评估"></a>方法评估</h1><p>在21,184个使用CNAME的网站中，有20,504个仅使用了提供非T/A服务CNAME。根据Virus Total，这些非T/A大多属于信息技术、商业和计算机及软件类别，包括CDN和虚拟主机服务。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/4941ede8-c1f7-4f34-bede-bab062c19044.png"><br>在评估Cookies泄露的时候由于每个分析站点都需要人工操作，因此作者将实验限制在10,000个最流行的域上。在过滤了金融服务和购物网站之后，作者使用119个域进行分析。其中的90个网站上作者手动创建了帐户用于测试。在这90个网站中，有27个将其会话cookie（我们确认该cookie提供了对用户帐户的访问）发送至隐匿的T/A服务。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/13366964-df26-49df-aae5-18865dffc844.png"></p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
            <tag> S&amp;P 2021 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PR - Oversharing Is Not Caring: How CNAME Cloaking Can ExposeYour Session Cookies</title>
      <link href="/2020/05/25/Oversharing%20Is%20Not%20Caring/"/>
      <url>/2020/05/25/Oversharing%20Is%20Not%20Caring/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>原文作者：Assel Aliyeva, Manuel Egele</em></p><p><em>原文标题: Oversharing Is Not Caring: How CNAME Cloaking Can ExposeYour Session Cookies</em></p><p><em>原文链接: <a href="https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf">https://seclab.bu.edu/papers/cname_cloaking-asiaccs2021.pdf</a></em></p><p><em>原文来源: AsiaCCS 2021</em></p><p><em>笔记作者：outx</em></p></blockquote><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>互联网发展至今，一些在线业务通常会利用第三方的分析服务来深入了解其用户的行为。但由于隐私保护的发展及浏览器同源策略的限制，这在很大程度上限制了第三方Cookie的跟踪和使用。于是，企业开始尝试将第三方分析服务伪装成其网站的子域。这种被称为是CNAME伪装的技术使得企业能够继续监测其网站上的用户活动。但随之而来的是严重的安全隐患，因为企业与这些第三方分析服务提供商共享了用户会话Cookie，这使得在线用户的账户始终处于不安全的状态。在这篇文章中，作者演示了CNAME伪装以及Lax Cookie访问控制设置对Web用户安全性的影响。为了解决这一问题，作者构建了一个可以检测伪装为子域的第三方分析服务以及第一方Cookie泄露的工具TAFinder。</p><h1 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h1><ul><li>确定了第一方Cookie泄露给T/A(跟踪和广告)服务提供商的情况</li><li>构建了TAFinder用于自动识别网站中是否存在隐匿域并检测这些Cookie是否泄漏到这些域</li><li>针对这些隐匿域提出了一种基于HTTP的Web分析域检测机制，达到了96％的准确率</li><li>确定了2,139个在野的Web分析域</li><li>对100,000个最受欢迎的网站进行了测试，发现2,271个网站使用CNAME伪装技术将第三方分析服务作为其子域</li></ul><h1 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h1><p><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/749afbc8-7bb7-4449-9adf-28f0710e32bb.png"><br>TAFinder主要分为三个单元：</p><ol><li>数据采集</li><li>DNS处理</li><li>基于机器学习的检测<h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2>以流水线的方式设计的TAFinder接受一个网站列表作为输入，然后由任务分配器将其分配给Worker。当从任务分配器中收到一个新的W(Website)时，一个Worker会生成一个新的爬虫实例。爬虫访问W，同时记录网络数据包和纯文本的HTTP请求/响应，并最终将捕获的数据传输给DNS处理单元。值得注意的是，Worker运行在独立的容器中，因此它允许TAFinder轻松地分离来自不同网站的网络流量。</li></ol><h2 id="DNS处理"><a href="#DNS处理" class="headerlink" title="DNS处理"></a>DNS处理</h2><p>TAFinder从任何给定的W中提取一组隐匿域CW。DNS处理单元对涉及CNAME的W的每个子域进行DNS解析链的遍历。如果一个解析链以属于第三方的CNAME结束，DNS处理单元将相应的子域标记为隐匿域D。</p><h2 id="基于机器学习的检测"><a href="#基于机器学习的检测" class="headerlink" title="基于机器学习的检测"></a>基于机器学习的检测</h2><p>TAFinder首先使用黑名单和Virus Total将CW中的域识别为T/A服务。为了将CW中剩余的未标记的隐匿域分类为T/A或非T/A，TAFinder部署了一种监督机器学习方法。为此，其设计了九种特征，以捕捉T/A服务固有的行为模式。这些特征是从访问W时与隐匿域的HTTP通信中提取的。<br>下面是九个特征:</p><ol><li>当加载W的所有资源时，以D为目标的HTTP请求的数量超过所有HTTP请求的数量</li><li>当加载W的所有资源时，来自D的HTTP响应的总大小超过所有HTTP响应大小的总和</li><li>D所设置的cookies总数</li><li>在D设置的所有cookies数量中，长cookies的数量</li><li>D设置的常规的非目标cookies的数量</li><li>D设置的常规的目标cookie的数量<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/8ab9b802-d526-4eb1-b228-85fe9b95ed0f.png"></li><li>在URL中使用的参数数量超过了以D为目标的HTTP请求的数量</li><li>目标为D的URL中包括W的域名作为参数值之一的次数</li><li>Content-Type特征<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/f4341811-3dc8-417f-a9d1-44d6ecc95c1a.png"></li></ol><p><strong>特征重要性排序</strong><br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/b679fc1b-c741-44e2-8eb2-6ae183fcebcd.png"></p><h1 id="系统实现"><a href="#系统实现" class="headerlink" title="系统实现"></a>系统实现</h1><h2 id="数据采集和DNS处理"><a href="#数据采集和DNS处理" class="headerlink" title="数据采集和DNS处理"></a>数据采集和DNS处理</h2><p>在数据采集单元，TAFinder采用了RabbitMQ来实现任务分配，这使得作者可以并行扩展和运行10个Worker。每个Worker由一个独立运行的Linux容器表示，这些容器均配置好了Tcpdump和MitmProxy用于记录网络数据包和纯文本的HTTP请求/响应。Worker使用一个基于selenium的爬虫来启动对每个单独的网站的爬取。在爬取完毕后销毁实例，压缩并将捕获到的数据存储下来。在DNS处理单元则使用了Python的Scapy库分别提取每个网站的隐匿域。</p><h2 id="基于机器学习的检测-1"><a href="#基于机器学习的检测-1" class="headerlink" title="基于机器学习的检测"></a>基于机器学习的检测</h2><p>TAFinder是靠一份T/A列表（来源包括了已被标记的第三方分析服务提供商和VirusTotal等）来标记要提取的隐匿域。同时，根据VirusTotal提供的类别来标记数据集中的在野隐匿域。</p><p>TAFinder使用MitmProxy的Python模块解析这些数据，并从中提取特征。同时。鉴于有一大批不同的cookie名称需要分类，TAFinder只选取那些最流行的cookie。为此，作者提取了所有隐匿域的HTTP响应中的cookie名称。然后，根据发送cookie的隐匿域的数量对cookie进行排名。以同样的方式，作者又创建了两个流行度排名，专门针对非T/A和T/A服务设置的cookies。</p><p>作者从上面cookie排名中选中了最受欢迎的25个cookie，以及60个隶属于T/A和非T/A域的cookie名称。根据One Trust的cookie分类，作者将这些cookie归类为T/A cookie，然后通过Cookiepedia或T/A特定的方式进行访问。基于这种方法，作者发现了27个跟踪相关的cookies和28个默认的网络应用程序cookies。</p><p>为了对隐匿域进行分类，TAFinder使用Scikit-Learn的随机森林模型。</p><h1 id="方法评估"><a href="#方法评估" class="headerlink" title="方法评估"></a>方法评估</h1><p>在21,184个使用CNAME的网站中，有20,504个仅使用了提供非T/A服务CNAME。根据Virus Total，这些非T/A大多属于信息技术、商业和计算机及软件类别，包括CDN和虚拟主机服务。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/4941ede8-c1f7-4f34-bede-bab062c19044.png"><br>在评估Cookies泄露的时候由于每个分析站点都需要人工操作，因此作者将实验限制在10,000个最流行的域上。在过滤了金融服务和购物网站之后，作者使用119个域进行分析。其中的90个网站上作者手动创建了帐户用于测试。在这90个网站中，有27个将其会话cookie（我们确认该cookie提供了对用户帐户的访问）发送至隐匿的T/A服务。<br><img src="https://blog-1253481369.cos.ap-chengdu.myqcloud.com/img/13366964-df26-49df-aae5-18865dffc844.png"></p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
            <tag> AsiaCCS 2021 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
